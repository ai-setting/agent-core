# LLM Configuration
# Format: <provider>/<model> (e.g., "openai/gpt-4o", "kimi/kimi-k2.5", "deepseek/deepseek-chat")
LLM_MODEL=openai/gpt-4o

# API Key (optional, can also be set via provider-specific env vars like OPENAI_API_KEY)
LLM_API_KEY=

# Custom Base URL (optional, for proxies or custom endpoints)
# LLM_BASE_URL=https://api.openai.com/v1
